{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11a03e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Images in: C:\\Users\\tasep\\OneDrive\\Documentos\\Lyon TI\\PDF417\\out_pdf417_cols20_csv_noise\n",
      "✅ CSV (image,text) at: C:\\Users\\tasep\\OneDrive\\Documentos\\Lyon TI\\PDF417\\out_pdf417_cols20_csv_noise\\mapping.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Synthetic SII-like TED -> PDF417 -> PNG/JPG\n",
    "# CSV = (image, text) where text is the FULL payload string used for that image\n",
    "# Columns ~ 20 (+/-): target 20, allow 18..22\n",
    "# + Randomized \"camera/scan\" degradations BEFORE saving:\n",
    "#   - gaussian blur (mild)\n",
    "#   - color changes (brightness/contrast/saturation + slight hue shift)\n",
    "#   - salt & pepper (mild)\n",
    "#   - perspective \"trapezoid\" / keystone (mild)\n",
    "#   - small rotation + shear\n",
    "#   - yellowing (paper tint)\n",
    "#   - optional downscale->upscale (softening)\n",
    "#\n",
    "# Jupyter:\n",
    "#   %pip install pdf417gen pillow numpy\n",
    "# ============================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, date, timedelta\n",
    "from pathlib import Path\n",
    "import base64\n",
    "import hashlib\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import csv\n",
    "from typing import Tuple, Optional, List\n",
    "\n",
    "import pdf417gen\n",
    "from PIL import Image, ImageFilter, ImageEnhance, ImageChops\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Utilities\n",
    "# ----------------------------\n",
    "def safe_filename(s: str, max_len: int = 150) -> str:\n",
    "    s = (s or \"\").strip()\n",
    "    s = re.sub(r\"[^\\w\\-.]+\", \"_\", s)\n",
    "    return (s[:max_len] or \"barcode\")\n",
    "\n",
    "def weighted_choice(items, weights):\n",
    "    return random.choices(items, weights=weights, k=1)[0]\n",
    "\n",
    "def rand_alnum(n: int) -> str:\n",
    "    return \"\".join(random.choice(string.ascii_uppercase + string.digits) for _ in range(n))\n",
    "\n",
    "def rand_digits(n: int) -> str:\n",
    "    return \"\".join(random.choice(string.digits) for _ in range(n))\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Accents + capitalization randomization\n",
    "# ----------------------------\n",
    "VOWEL_ACCENTS = {\n",
    "    \"a\": [\"a\", \"á\"], \"e\": [\"e\", \"é\"], \"i\": [\"i\", \"í\"], \"o\": [\"o\", \"ó\"], \"u\": [\"u\", \"ú\"],\n",
    "    \"A\": [\"A\", \"Á\"], \"E\": [\"E\", \"É\"], \"I\": [\"I\", \"Í\"], \"O\": [\"O\", \"Ó\"], \"U\": [\"U\", \"Ú\"],\n",
    "}\n",
    "\n",
    "def randomize_accents(text: str, prob: float = 0.15) -> str:\n",
    "    out = []\n",
    "    for ch in text:\n",
    "        if ch in VOWEL_ACCENTS and random.random() < prob:\n",
    "            out.append(random.choice(VOWEL_ACCENTS[ch]))\n",
    "        else:\n",
    "            out.append(ch)\n",
    "    return \"\".join(out)\n",
    "\n",
    "def randomize_case(text: str) -> str:\n",
    "    mode = random.choice([\"lower\", \"upper\", \"title\", \"mixed\", \"original\"])\n",
    "    if mode == \"lower\":\n",
    "        return text.lower()\n",
    "    if mode == \"upper\":\n",
    "        return text.upper()\n",
    "    if mode == \"title\":\n",
    "        return text.title()\n",
    "    if mode == \"mixed\":\n",
    "        return \"\".join(ch.upper() if random.random() < 0.5 else ch.lower() for ch in text)\n",
    "    return text\n",
    "\n",
    "def spanish_noise(text: str, accent_prob: float = 0.15, apply_case: bool = True) -> str:\n",
    "    if not text:\n",
    "        return text\n",
    "    t = randomize_accents(text, accent_prob)\n",
    "    if apply_case:\n",
    "        t = randomize_case(t)\n",
    "    return t\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3) RUT generation (valid DV)\n",
    "# ----------------------------\n",
    "def rut_dv(rut_number: int) -> str:\n",
    "    total = 0\n",
    "    mult = 2\n",
    "    n = rut_number\n",
    "    while n > 0:\n",
    "        total += (n % 10) * mult\n",
    "        n //= 10\n",
    "        mult = 2 if mult == 7 else mult + 1\n",
    "    r = 11 - (total % 11)\n",
    "    if r == 11:\n",
    "        return \"0\"\n",
    "    if r == 10:\n",
    "        return \"K\"\n",
    "    return str(r)\n",
    "\n",
    "def random_rut(min_rut: int = 5_000_000, max_rut: int = 90_000_000) -> str:\n",
    "    n = random.randint(min_rut, max_rut)\n",
    "    return f\"{n}-{rut_dv(n)}\"\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Synthetic data pools\n",
    "# ----------------------------\n",
    "TIPOS_DTE = [\"33\", \"34\", \"39\", \"61\", \"56\"]\n",
    "TIPOS_DTE_W = [0.55, 0.10, 0.25, 0.06, 0.04]\n",
    "\n",
    "WORDS = [\n",
    "    \"SERVICIO\",\"INSUMO\",\"EQUIPO\",\"REPUESTO\",\"MANTENCION\",\"FILTRO\",\"SENSOR\",\"CABLE\",\"BATERIA\",\"VALVULA\",\n",
    "    \"KIT\",\"MODULO\",\"PACK\",\"TUBO\",\"BOLSA\",\"GUANTE\",\"MASCARILLA\",\"CATETER\",\"JERINGA\",\"SOLUCION\",\"PRUEBA\",\n",
    "    \"DIAGNOSTICO\",\"CALIBRACION\",\"INSTALACION\",\"TRANSPORTE\",\"ARRIENDO\",\"MONITOREO\",\"REPARACION\",\"COMUNICACION\",\n",
    "    \"SOPORTE\",\"ACTUALIZACION\",\"LICENCIA\",\"SOFTWARE\",\"HARDWARE\",\"PROCEDIMIENTO\",\"CLINICO\",\"HOSPITALARIO\"\n",
    "]\n",
    "SUFFIX = [\"SpA\",\"Ltda\",\"S.A.\",\"EIRL\",\"Limitada\"]\n",
    "GIROS = [\"Servicios Medicos\",\"Mantenimiento Equipos\",\"Insumos Clinicos\",\"Tecnologia Medica\",\"Servicios TI\",\"Logistica\"]\n",
    "COMUNAS = [\"VALPARAISO\",\"VINA DEL MAR\",\"QUILPUE\",\"VILLA ALEMANA\",\"SAN ANTONIO\",\"LOS ANDES\",\"LA CALERA\",\"LIMACHE\"]\n",
    "REGIONES = [\"VALPARAISO\",\"METROPOLITANA\",\"BIOBIO\",\"COQUIMBO\",\"ARAUCANIA\"]\n",
    "\n",
    "def rand_text_words(min_w: int, max_w: int) -> str:\n",
    "    return \" \".join(random.choice(WORDS) for _ in range(random.randint(min_w, max_w)))\n",
    "\n",
    "def rand_company(max_len: int = 60) -> str:\n",
    "    base = rand_text_words(1, 4)\n",
    "    name = f\"{base} {random.choice(SUFFIX)}\"\n",
    "    if random.random() < 0.40:\n",
    "        name += f\" {random.randint(1, 999)}\"\n",
    "    if random.random() < 0.25:\n",
    "        name = name.replace(\" \", \"-\")\n",
    "    return name[:max_len]\n",
    "\n",
    "def rand_address(max_len: int = 80) -> str:\n",
    "    street = random.choice([\"AV\", \"CALLE\", \"PASAJE\", \"CAMINO\", \"RUTA\"])\n",
    "    nm = random.choice([\"LIBERTAD\", \"ESPAÑA\", \"ARGENTINA\", \"COLON\", \"PRAT\", \"CENTRAL\", \"NORTE\", \"SUR\"])\n",
    "    addr = f\"{street} {nm} {random.randint(1,9999)}\"\n",
    "    if random.random() < 0.35:\n",
    "        addr += f\" OF {random.randint(1, 999)}\"\n",
    "    return addr[:max_len]\n",
    "\n",
    "def rand_amount_clp(min_amt: int = 500, max_amt: int = 50_000_000) -> int:\n",
    "    x = random.random() ** 2.0\n",
    "    amt = int(min_amt + x * (max_amt - min_amt))\n",
    "    step = weighted_choice([10, 100, 1000, 10000], [0.10, 0.35, 0.35, 0.20])\n",
    "    return max(min_amt, (amt // step) * step)\n",
    "\n",
    "def rand_issue_date(days_back: int = 365) -> date:\n",
    "    return date.today() - timedelta(days=random.randint(0, days_back))\n",
    "\n",
    "def rand_tsted(days_back: int = 365) -> datetime:\n",
    "    return datetime.now() - timedelta(seconds=random.randint(0, days_back * 24 * 3600))\n",
    "\n",
    "def rand_item_line(max_len: int = 180) -> str:\n",
    "    desc = rand_text_words(3, 12)\n",
    "    code = f\"{random.choice(['SKU','REF','COD','INT'])}-{rand_digits(random.randint(4,7))}\"\n",
    "    um = random.choice([\"UN\",\"CJ\",\"PK\",\"HRS\",\"DIA\",\"MES\"])\n",
    "    qty = random.randint(1, 25)\n",
    "    return f\"{desc} {code} {qty}{um}\"[:max_len]\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Synthetic CAF + FRMT (bounded)\n",
    "# ----------------------------\n",
    "def fake_caf_xml() -> str:\n",
    "    core = rand_alnum(16)\n",
    "    extra = rand_alnum(random.choice([120, 160, 200, 240]))\n",
    "    return (\n",
    "        f'<CAF version=\"1.0\"><DA>'\n",
    "        f'<RE>{random_rut()}</RE><TD>{weighted_choice(TIPOS_DTE, TIPOS_DTE_W)}</TD>'\n",
    "        f'<RNG><D>{random.randint(1,5000)}</D><H>{random.randint(5001,9_999_999)}</H></RNG>'\n",
    "        f'<FA>{date.today().strftime(\"%Y-%m-%d\")}</FA>'\n",
    "        f'<RSAPK><M>{core}{extra}</M><E>65537</E></RSAPK>'\n",
    "        f'</DA></CAF>'\n",
    "    )\n",
    "\n",
    "def fake_frmt(dd_xml: str) -> str:\n",
    "    d1 = hashlib.sha256(dd_xml.encode(\"utf-8\")).digest()\n",
    "    d2 = hashlib.sha1(dd_xml.encode(\"utf-8\")).digest()\n",
    "    return base64.b64encode(d1 + d2).decode(\"ascii\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 6) TED builder (heavy-ish, varied)\n",
    "# ----------------------------\n",
    "def build_ted_xml(\n",
    "    rut_emisor: str,\n",
    "    tipo_dte: str,\n",
    "    folio: int,\n",
    "    fe: date,\n",
    "    rut_receptor: str,\n",
    "    days_back: int,\n",
    "    accent_prob: float,\n",
    "    items_min: int,\n",
    "    items_max: int,\n",
    ") -> str:\n",
    "    rsr  = spanish_noise(rand_company(60), accent_prob=accent_prob)[:40]\n",
    "    giro = spanish_noise(random.choice(GIROS), accent_prob=accent_prob)[:40]\n",
    "    dirr = spanish_noise(rand_address(80), accent_prob=accent_prob * 0.6)[:70]\n",
    "    cmna = spanish_noise(random.choice(COMUNAS), accent_prob=accent_prob * 0.4)[:20]\n",
    "    rgn  = spanish_noise(random.choice(REGIONES), accent_prob=accent_prob * 0.4)[:20]\n",
    "\n",
    "    items = [\n",
    "        spanish_noise(rand_item_line(180), accent_prob=accent_prob * 0.7)\n",
    "        for _ in range(random.randint(items_min, items_max))\n",
    "    ]\n",
    "    it1 = items[0][:40]\n",
    "\n",
    "    mnt  = rand_amount_clp()\n",
    "    neto = int(mnt * random.uniform(0.70, 0.95)) // 10 * 10\n",
    "    iva  = max(0, mnt - neto)\n",
    "\n",
    "    tsted = rand_tsted(days_back).strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "    fe_str = fe.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    obs = spanish_noise(rand_text_words(10, 22), accent_prob=accent_prob)[:220]\n",
    "    ref_fe = rand_issue_date(days_back).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    caf = fake_caf_xml()\n",
    "\n",
    "    dd = (\n",
    "        f\"<DD>\"\n",
    "        f\"<RE>{rut_emisor}</RE><TD>{tipo_dte}</TD><F>{folio}</F><FE>{fe_str}</FE>\"\n",
    "        f\"<RR>{rut_receptor}</RR><RSR>{rsr}</RSR>\"\n",
    "        f\"<GIR>{giro}</GIR><DIRR>{dirr}</DIRR><CMNA>{cmna}</CMNA><REG>{rgn}</REG>\"\n",
    "        f\"<MNT>{mnt}</MNT><NETO>{neto}</NETO><IVA>{iva}</IVA>\"\n",
    "        f\"<IT1>{it1}</IT1>\"\n",
    "        f\"<OBS>{obs}</OBS>\"\n",
    "        f\"<REF><TPO>801</TPO><FOL>{random.randint(1,999999)}</FOL><FE>{ref_fe}</FE></REF>\"\n",
    "        f\"{caf}\"\n",
    "        f\"<TSTED>{tsted}</TSTED>\"\n",
    "        f\"</DD>\"\n",
    "    )\n",
    "\n",
    "    frmt = fake_frmt(dd)\n",
    "    return f'<TED version=\"1.0\">{dd}<FRMT algoritmo=\"SHA1withRSA\">{frmt}</FRMT></TED>'\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 7) PDF417 policies: ~20 columns (+/-)\n",
    "# ----------------------------\n",
    "@dataclass\n",
    "class ColPolicy:\n",
    "    min_cols: int = 18\n",
    "    preferred_cols: int = 20\n",
    "    max_cols: int = 22\n",
    "    preferred_security: int = 4\n",
    "    min_security: int = 2\n",
    "    allow_reduce_security: bool = True\n",
    "\n",
    "@dataclass\n",
    "class SplitPolicy:\n",
    "    enabled: bool = True\n",
    "    chunk_chars: int = 700\n",
    "    add_header: bool = True\n",
    "\n",
    "@dataclass\n",
    "class PadPolicy:\n",
    "    enabled: bool = True\n",
    "    pad_chunk: int = 220\n",
    "    pad_max_rounds: int = 25\n",
    "\n",
    "\n",
    "def _encode(payload: str, cols: int, sec: int):\n",
    "    return pdf417gen.encode(payload, columns=cols, security_level=sec)\n",
    "\n",
    "def encode_with_cols(payload: str, cp: ColPolicy):\n",
    "    for cols in range(max(cp.preferred_cols, cp.min_cols), cp.max_cols + 1):\n",
    "        try:\n",
    "            return _encode(payload, cols, cp.preferred_security), cols, cp.preferred_security\n",
    "        except ValueError as e:\n",
    "            msg = str(e)\n",
    "            if \"Maximum is 90 rows\" in msg:\n",
    "                continue\n",
    "            if \"Data too long\" in msg:\n",
    "                raise\n",
    "            if \"Minimum is\" in msg:\n",
    "                raise\n",
    "            raise\n",
    "\n",
    "    if cp.allow_reduce_security:\n",
    "        for sec in range(cp.preferred_security - 1, cp.min_security - 1, -1):\n",
    "            for cols in range(max(cp.preferred_cols, cp.min_cols), cp.max_cols + 1):\n",
    "                try:\n",
    "                    return _encode(payload, cols, sec), cols, sec\n",
    "                except ValueError as e:\n",
    "                    msg = str(e)\n",
    "                    if \"Maximum is 90 rows\" in msg:\n",
    "                        continue\n",
    "                    if \"Data too long\" in msg:\n",
    "                        raise\n",
    "                    if \"Minimum is\" in msg:\n",
    "                        raise\n",
    "                    raise\n",
    "\n",
    "    raise ValueError(\"Could not encode within constraints.\")\n",
    "\n",
    "def pad_to_min_rows(payload: str, cp: ColPolicy, pp: PadPolicy) -> str:\n",
    "    if not pp.enabled:\n",
    "        return payload\n",
    "    p = payload\n",
    "    for _ in range(pp.pad_max_rounds):\n",
    "        try:\n",
    "            encode_with_cols(p, cp)\n",
    "            return p\n",
    "        except ValueError as e:\n",
    "            msg = str(e)\n",
    "            if \"Minimum is\" in msg and \"Try decreasing column count\" in msg:\n",
    "                p += f\"<PAD>{rand_alnum(pp.pad_chunk)}</PAD>\"\n",
    "                continue\n",
    "            raise\n",
    "    raise ValueError(\"Could not reach minimum rows with padding. Increase pad_chunk.\")\n",
    "\n",
    "def split_payload(payload: str, sp: SplitPolicy) -> List[str]:\n",
    "    parts = [payload[i:i+sp.chunk_chars] for i in range(0, len(payload), sp.chunk_chars)]\n",
    "    if not sp.add_header:\n",
    "        return parts\n",
    "    total = len(parts)\n",
    "    return [f\"[PART {i+1}/{total}]\" + parts[i] for i in range(total)]\n",
    "\n",
    "def encode_payload(payload: str, cp: ColPolicy, sp: SplitPolicy, pp: PadPolicy):\n",
    "    try:\n",
    "        p1 = pad_to_min_rows(payload, cp, pp)\n",
    "        codes, cols, sec = encode_with_cols(p1, cp)\n",
    "        return [(p1, codes, cols, sec, 1, 1)]\n",
    "    except ValueError as e:\n",
    "        if \"Data too long\" not in str(e):\n",
    "            raise\n",
    "        if not sp.enabled:\n",
    "            raise\n",
    "\n",
    "    parts = split_payload(payload, sp)\n",
    "    out = []\n",
    "    total = len(parts)\n",
    "    for i, part in enumerate(parts, start=1):\n",
    "        part2 = pad_to_min_rows(part, cp, pp)\n",
    "        try:\n",
    "            codes, cols, sec = encode_with_cols(part2, cp)\n",
    "            out.append((part2, codes, cols, sec, i, total))\n",
    "        except ValueError as e:\n",
    "            msg = str(e)\n",
    "            if \"Data too long\" in msg:\n",
    "                new_chunk = max(240, sp.chunk_chars // 2)\n",
    "                return encode_payload(payload, cp, SplitPolicy(True, new_chunk, sp.add_header), pp)\n",
    "            raise\n",
    "    return out\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 8) Image degradations (mild, randomized)\n",
    "# ----------------------------\n",
    "@dataclass\n",
    "class NoiseConfig:\n",
    "    enabled: bool = True\n",
    "\n",
    "    # probabilities (0..1)\n",
    "    p_blur: float = 0.65\n",
    "    p_color: float = 0.70\n",
    "    p_saltpepper: float = 0.55\n",
    "    p_gaussian: float = 0.45\n",
    "    p_perspective: float = 0.55\n",
    "    p_rotate: float = 0.55\n",
    "    p_yellow: float = 0.55\n",
    "    p_resample: float = 0.35\n",
    "\n",
    "    # ranges (kept mild to preserve readability)\n",
    "    blur_radius: Tuple[float, float] = (0.0, 1.2)\n",
    "    brightness: Tuple[float, float] = (0.92, 1.08)\n",
    "    contrast: Tuple[float, float] = (0.92, 1.10)\n",
    "    saturation: Tuple[float, float] = (0.85, 1.15)\n",
    "    hue_shift_deg: Tuple[float, float] = (-6.0, 6.0)\n",
    "\n",
    "    saltpepper_amount: Tuple[float, float] = (0.0005, 0.008)  # fraction of pixels\n",
    "    gaussian_sigma: Tuple[float, float] = (0.0, 8.0)          # noise std in 0..255 scale (mild)\n",
    "\n",
    "    rotate_deg: Tuple[float, float] = (-2.0, 2.0)\n",
    "    shear_x: Tuple[float, float] = (-0.04, 0.04)              # affine shear (mild)\n",
    "    shear_y: Tuple[float, float] = (-0.02, 0.02)\n",
    "\n",
    "    perspective_strength: Tuple[float, float] = (0.01, 0.07)   # keystone amount (fraction of width/height)\n",
    "\n",
    "    yellow_strength: Tuple[float, float] = (0.03, 0.18)\n",
    "\n",
    "    # Downscale-upscale\n",
    "    resample_scale: Tuple[float, float] = (0.88, 0.98)        # 12% max downscale\n",
    "\n",
    "\n",
    "def _clamp_u8(a: np.ndarray) -> np.ndarray:\n",
    "    return np.clip(a, 0, 255).astype(np.uint8)\n",
    "\n",
    "def _hue_shift_rgb(img: Image.Image, deg: float) -> Image.Image:\n",
    "    # Convert to HSV, shift hue channel\n",
    "    hsv = img.convert(\"HSV\")\n",
    "    arr = np.array(hsv, dtype=np.uint8)\n",
    "    # Hue in PIL HSV is 0..255 corresponding to 0..360 deg\n",
    "    shift = int((deg / 360.0) * 255) % 255\n",
    "    arr[..., 0] = (arr[..., 0].astype(int) + shift) % 255\n",
    "    return Image.fromarray(arr, mode=\"HSV\").convert(\"RGB\")\n",
    "\n",
    "def _add_gaussian_noise(img: Image.Image, sigma: float) -> Image.Image:\n",
    "    if sigma <= 0:\n",
    "        return img\n",
    "    arr = np.array(img, dtype=np.float32)\n",
    "    noise = np.random.normal(0.0, sigma, size=arr.shape).astype(np.float32)\n",
    "    arr2 = _clamp_u8(arr + noise)\n",
    "    return Image.fromarray(arr2, mode=\"RGB\")\n",
    "\n",
    "def _add_salt_pepper(img: Image.Image, amount: float) -> Image.Image:\n",
    "    if amount <= 0:\n",
    "        return img\n",
    "    arr = np.array(img, dtype=np.uint8)\n",
    "    h, w, _ = arr.shape\n",
    "    n = int(h * w * amount)\n",
    "    if n <= 0:\n",
    "        return img\n",
    "    # half salt half pepper\n",
    "    ys = np.random.randint(0, h, size=n)\n",
    "    xs = np.random.randint(0, w, size=n)\n",
    "    salt_mask = np.random.rand(n) < 0.5\n",
    "    arr[ys[salt_mask], xs[salt_mask]] = 255\n",
    "    arr[ys[~salt_mask], xs[~salt_mask]] = 0\n",
    "    return Image.fromarray(arr, mode=\"RGB\")\n",
    "\n",
    "def _apply_yellowing(img: Image.Image, strength: float) -> Image.Image:\n",
    "    # Blend with a warm paper tone\n",
    "    if strength <= 0:\n",
    "        return img\n",
    "    overlay = Image.new(\"RGB\", img.size, (255, 244, 214))  # mild yellow paper\n",
    "    return Image.blend(img, overlay, alpha=float(strength))\n",
    "\n",
    "def _affine_shear(img: Image.Image, shx: float, shy: float) -> Image.Image:\n",
    "    w, h = img.size\n",
    "    # PIL affine: (a, b, c, d, e, f) mapping x' = a*x + b*y + c ; y' = d*x + e*y + f\n",
    "    a = 1.0\n",
    "    b = shx\n",
    "    d = shy\n",
    "    e = 1.0\n",
    "    # shift to keep content in frame\n",
    "    c = -b * h / 2\n",
    "    f = -d * w / 2\n",
    "    return img.transform((w, h), Image.AFFINE, (a, b, c, d, e, f), resample=Image.BICUBIC)\n",
    "\n",
    "def _perspective_coeffs(src, dst):\n",
    "    # Solve for perspective transform coefficients\n",
    "    # src/dst are [(x,y)*4]\n",
    "    A = []\n",
    "    B = []\n",
    "    for (x, y), (u, v) in zip(src, dst):\n",
    "        A.append([x, y, 1, 0, 0, 0, -u*x, -u*y])\n",
    "        A.append([0, 0, 0, x, y, 1, -v*x, -v*y])\n",
    "        B.append(u)\n",
    "        B.append(v)\n",
    "    A = np.array(A, dtype=np.float64)\n",
    "    B = np.array(B, dtype=np.float64)\n",
    "    coeffs = np.linalg.lstsq(A, B, rcond=None)[0]\n",
    "    return tuple(coeffs.tolist())\n",
    "\n",
    "def _trapezoid_perspective(img: Image.Image, strength: float) -> Image.Image:\n",
    "    if strength <= 0:\n",
    "        return img\n",
    "    w, h = img.size\n",
    "    dx = w * strength\n",
    "    dy = h * strength * 0.7\n",
    "\n",
    "    # random trapezoid direction\n",
    "    top_in = random.random() < 0.5\n",
    "    left_in = random.random() < 0.5\n",
    "\n",
    "    # Build destination quad\n",
    "    # Start as rectangle corners:\n",
    "    # (0,0) (w,0) (w,h) (0,h)\n",
    "    # then move corners slightly\n",
    "    if top_in:\n",
    "        tlx = dx if left_in else 0\n",
    "        trx = w - (0 if left_in else dx)\n",
    "    else:\n",
    "        tlx = 0\n",
    "        trx = w\n",
    "\n",
    "    if not top_in:\n",
    "        # bottom in\n",
    "        blx = dx if left_in else 0\n",
    "        brx = w - (0 if left_in else dx)\n",
    "    else:\n",
    "        blx = 0\n",
    "        brx = w\n",
    "\n",
    "    # vertical skew\n",
    "    tly = dy * (random.random() * 0.8)\n",
    "    try_ = dy * (random.random() * 0.8)\n",
    "    bly = h - dy * (random.random() * 0.8)\n",
    "    bry = h - dy * (random.random() * 0.8)\n",
    "\n",
    "    src = [(0,0), (w,0), (w,h), (0,h)]\n",
    "    dst = [(tlx, tly), (trx, try_), (brx, bry), (blx, bly)]\n",
    "    coeffs = _perspective_coeffs(src, dst)\n",
    "    return img.transform((w, h), Image.PERSPECTIVE, coeffs, resample=Image.BICUBIC)\n",
    "\n",
    "def _down_up_sample(img: Image.Image, scale: float) -> Image.Image:\n",
    "    if not (0 < scale < 1):\n",
    "        return img\n",
    "    w, h = img.size\n",
    "    w2 = max(1, int(w * scale))\n",
    "    h2 = max(1, int(h * scale))\n",
    "    small = img.resize((w2, h2), resample=Image.BILINEAR)\n",
    "    return small.resize((w, h), resample=Image.BILINEAR)\n",
    "\n",
    "def apply_random_degradations(img: Image.Image, nc: NoiseConfig) -> Image.Image:\n",
    "    if not nc.enabled:\n",
    "        return img\n",
    "\n",
    "    # work in RGB\n",
    "    im = img.convert(\"RGB\")\n",
    "\n",
    "    # Small rotation (expand=False to keep same size)\n",
    "    if random.random() < nc.p_rotate:\n",
    "        deg = random.uniform(*nc.rotate_deg)\n",
    "        im = im.rotate(deg, resample=Image.BICUBIC, expand=False, fillcolor=(255, 255, 255))\n",
    "\n",
    "    # Shear\n",
    "    if random.random() < 0.35:\n",
    "        shx = random.uniform(*nc.shear_x)\n",
    "        shy = random.uniform(*nc.shear_y)\n",
    "        im = _affine_shear(im, shx, shy)\n",
    "\n",
    "    # Perspective trapezoid / keystone\n",
    "    if random.random() < nc.p_perspective:\n",
    "        strength = random.uniform(*nc.perspective_strength)\n",
    "        im = _trapezoid_perspective(im, strength)\n",
    "\n",
    "    # Color jitter (mild)\n",
    "    if random.random() < nc.p_color:\n",
    "        im = ImageEnhance.Brightness(im).enhance(random.uniform(*nc.brightness))\n",
    "        im = ImageEnhance.Contrast(im).enhance(random.uniform(*nc.contrast))\n",
    "        im = ImageEnhance.Color(im).enhance(random.uniform(*nc.saturation))\n",
    "        # slight hue shift\n",
    "        if random.random() < 0.45:\n",
    "            im = _hue_shift_rgb(im, random.uniform(*nc.hue_shift_deg))\n",
    "\n",
    "    # Yellowing\n",
    "    if random.random() < nc.p_yellow:\n",
    "        im = _apply_yellowing(im, random.uniform(*nc.yellow_strength))\n",
    "\n",
    "    # Down-up resample softening\n",
    "    if random.random() < nc.p_resample:\n",
    "        im = _down_up_sample(im, random.uniform(*nc.resample_scale))\n",
    "\n",
    "    # Gaussian blur\n",
    "    if random.random() < nc.p_blur:\n",
    "        r = random.uniform(*nc.blur_radius)\n",
    "        if r > 0:\n",
    "            im = im.filter(ImageFilter.GaussianBlur(radius=r))\n",
    "\n",
    "    # Gaussian pixel noise\n",
    "    if random.random() < nc.p_gaussian:\n",
    "        sigma = random.uniform(*nc.gaussian_sigma)\n",
    "        if sigma > 0.1:\n",
    "            im = _add_gaussian_noise(im, sigma=sigma)\n",
    "\n",
    "    # Salt & pepper\n",
    "    if random.random() < nc.p_saltpepper:\n",
    "        amt = random.uniform(*nc.saltpepper_amount)\n",
    "        if amt > 0:\n",
    "            im = _add_salt_pepper(im, amt)\n",
    "\n",
    "    return im\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 9) Rendering (with degradations)\n",
    "# ----------------------------\n",
    "@dataclass\n",
    "class RenderConfig:\n",
    "    fmt: str = \"PNG\"\n",
    "    scale: int = 8\n",
    "    ratio: int = 3\n",
    "    padding: int = 22\n",
    "    quality: int = 95\n",
    "    add_noise: bool = True\n",
    "\n",
    "def render_pdf417_image(codes, rcfg: RenderConfig) -> Image.Image:\n",
    "    # pdf417gen returns a PIL image (usually \"1\" or \"L\")\n",
    "    img = pdf417gen.render_image(codes, scale=rcfg.scale, ratio=rcfg.ratio, padding=rcfg.padding)\n",
    "    return img\n",
    "\n",
    "def save_image_with_noise(img: Image.Image, out_path: Path, rcfg: RenderConfig, nc: NoiseConfig) -> None:\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    im = img\n",
    "    if rcfg.add_noise:\n",
    "        im = apply_random_degradations(im, nc)\n",
    "\n",
    "    fmt = rcfg.fmt.upper()\n",
    "    if fmt in (\"JPG\", \"JPEG\"):\n",
    "        if im.mode != \"RGB\":\n",
    "            im = im.convert(\"RGB\")\n",
    "        im.save(out_path, format=\"JPEG\", quality=rcfg.quality)\n",
    "    else:\n",
    "        # PNG\n",
    "        if im.mode not in (\"RGB\", \"RGBA\"):\n",
    "            im = im.convert(\"RGB\")\n",
    "        im.save(out_path, format=\"PNG\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 10) Bulk generation + CSV(image,text)\n",
    "# ----------------------------\n",
    "@dataclass\n",
    "class GenConfig:\n",
    "    n: int = 200\n",
    "    out_dir: str = \"out_pdf417_cols20_csv_noise\"\n",
    "    csv_name: str = \"mapping.csv\"\n",
    "\n",
    "    days_back: int = 365\n",
    "    randomize_emisor: bool = True\n",
    "    fixed_emisor_rut: str = \"76123456-7\"\n",
    "\n",
    "    start_folio: int = 1\n",
    "    folio_jump_prob: float = 0.18\n",
    "    folio_jump_max: int = 50_000\n",
    "\n",
    "    accent_prob: float = 0.22\n",
    "    items_min: int = 8\n",
    "    items_max: int = 16\n",
    "\n",
    "\n",
    "def generate_many(\n",
    "    cfg: GenConfig,\n",
    "    cp: ColPolicy,\n",
    "    sp: SplitPolicy,\n",
    "    pp: PadPolicy,\n",
    "    rcfg: RenderConfig,\n",
    "    nc: NoiseConfig,\n",
    "    seed: Optional[int] = None,\n",
    "):\n",
    "    random.seed(seed if seed is not None else None)\n",
    "    np.random.seed(seed if seed is not None else None)\n",
    "\n",
    "    out_dir = Path(cfg.out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    csv_path = out_dir / cfg.csv_name\n",
    "    folio_state = cfg.start_folio\n",
    "\n",
    "    with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"image\", \"text\"])  # EXACTLY: (image, text)\n",
    "\n",
    "        for _ in range(cfg.n):\n",
    "            rut_emisor = random_rut() if cfg.randomize_emisor else cfg.fixed_emisor_rut\n",
    "            tipo_dte = weighted_choice(TIPOS_DTE, TIPOS_DTE_W)\n",
    "\n",
    "            if random.random() < cfg.folio_jump_prob:\n",
    "                folio_state += random.randint(2, cfg.folio_jump_max)\n",
    "            folio = folio_state\n",
    "            folio_state += 1\n",
    "\n",
    "            fe = rand_issue_date(cfg.days_back)\n",
    "            rut_receptor = random_rut()\n",
    "\n",
    "            payload = build_ted_xml(\n",
    "                rut_emisor=rut_emisor,\n",
    "                tipo_dte=tipo_dte,\n",
    "                folio=folio,\n",
    "                fe=fe,\n",
    "                rut_receptor=rut_receptor,\n",
    "                days_back=cfg.days_back,\n",
    "                accent_prob=cfg.accent_prob,\n",
    "                items_min=cfg.items_min,\n",
    "                items_max=cfg.items_max,\n",
    "            )\n",
    "\n",
    "            parts = encode_payload(payload, cp, sp, pp)\n",
    "\n",
    "            ext = \"png\" if rcfg.fmt.upper() == \"PNG\" else \"jpg\"\n",
    "            base = f\"TED_TD{tipo_dte}_F{folio}_{safe_filename(rut_emisor)}\"\n",
    "\n",
    "            for (payload_used, codes, cols, sec, pidx, ptotal) in parts:\n",
    "                if ptotal == 1:\n",
    "                    rel_img = Path(f\"{base}_c{cols}_s{sec}.{ext}\")\n",
    "                else:\n",
    "                    rel_img = Path(f\"{base}_c{cols}_s{sec}_p{pidx:03d}of{ptotal:03d}.{ext}\")\n",
    "\n",
    "                img_path = out_dir / rel_img\n",
    "\n",
    "                clean_img = render_pdf417_image(codes, rcfg)\n",
    "                save_image_with_noise(clean_img, img_path, rcfg, nc)\n",
    "\n",
    "                # CSV row: (image, FULL payload string encoded in THAT image)\n",
    "                w.writerow([str(rel_img).replace(\"\\\\\", \"/\"), payload_used])\n",
    "\n",
    "    print(f\"✅ Images in: {out_dir.resolve()}\")\n",
    "    print(f\"✅ CSV (image,text) at: {csv_path.resolve()}\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 11) RUN\n",
    "# ----------------------------\n",
    "cfg = GenConfig(\n",
    "    n=10,\n",
    "    out_dir=\"out_pdf417_cols20_csv_noise\",\n",
    "    csv_name=\"mapping.csv\",\n",
    "    accent_prob=0.22,\n",
    "    items_min=8,\n",
    "    items_max=16,\n",
    ")\n",
    "\n",
    "cp = ColPolicy(\n",
    "    min_cols=18,\n",
    "    preferred_cols=20,\n",
    "    max_cols=22,\n",
    "    preferred_security=4,\n",
    "    min_security=2,\n",
    "    allow_reduce_security=True,\n",
    ")\n",
    "\n",
    "sp = SplitPolicy(enabled=True, chunk_chars=700, add_header=True)\n",
    "pp = PadPolicy(enabled=True, pad_chunk=220, pad_max_rounds=25)\n",
    "\n",
    "rcfg = RenderConfig(fmt=\"PNG\", scale=8, ratio=3, padding=22, add_noise=True)\n",
    "\n",
    "# Noise stays mild so barcodes remain readable\n",
    "# Stronger: yellowing, blur, salt&pepper, gaussian (≈2x)\n",
    "# Slightly lighter: perspective\n",
    "\n",
    "nc = NoiseConfig(\n",
    "    enabled=True,\n",
    "\n",
    "    # probabilities (optional: keep same or slightly higher for the 4 effects)\n",
    "    p_blur=0.90,\n",
    "    p_color=0.70,\n",
    "    p_saltpepper=0.70,\n",
    "    p_gaussian=0.75,\n",
    "    p_perspective=0.45,\n",
    "    p_rotate=0.55,\n",
    "    p_yellow=0.80,\n",
    "    p_resample=0.35,\n",
    "\n",
    "    # 2x-ish strength\n",
    "    blur_radius=(0.5, 3),                 # was (0.0, 1.2)\n",
    "    gaussian_sigma=(1, 25.0),             # was (0.0, 8.0)\n",
    "    saltpepper_amount=(0.01, 0.02),       # was (0.0005, 0.008)\n",
    "    yellow_strength=(0.1, 0.36),           # was (0.03, 0.18)\n",
    "\n",
    "    # perspective slightly lighter\n",
    "    perspective_strength=(0.008, 0.012),     # was (0.01, 0.07)\n",
    "\n",
    "    # keep these as-is (or tweak if you want)\n",
    "    brightness=(0.92, 1.08),\n",
    "    contrast=(0.92, 1.10),\n",
    "    saturation=(0.85, 1.15),\n",
    "    hue_shift_deg=(-6.0, 6.0),\n",
    "    rotate_deg=(-2.0, 2.0),\n",
    "    shear_x=(-0.04, 0.04),\n",
    "    shear_y=(-0.02, 0.02),\n",
    "    resample_scale=(0.88, 0.98),\n",
    ")\n",
    "\n",
    "\n",
    "generate_many(cfg, cp, sp, pp, rcfg, nc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0432132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "johnny",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
